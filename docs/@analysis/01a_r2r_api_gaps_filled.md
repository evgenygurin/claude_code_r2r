# R2R API: –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ (Gap Analysis)

> **Supplement –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É**: 01_r2r_capabilities.md
>
> **–î–∞—Ç–∞**: 2025-11-19
>
> **–¶–µ–ª—å**: –ó–∞–ø–æ–ª–Ω–∏—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–µ–ª—ã, –≤—ã—è–≤–ª–µ–Ω–Ω—ã–µ –≤ Review

---

## –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [Collections API](#collections-api)
2. [Users & Authentication API](#users--authentication-api)
3. [Orchestration & Task Monitoring](#orchestration--task-monitoring)
4. [Streaming Support](#streaming-support)
5. [Rate Limiting & Performance](#rate-limiting--performance)
6. [–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑](#–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π-–∞–Ω–∞–ª–∏–∑)
7. [–í—ã–≤–æ–¥—ã –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏](#–≤—ã–≤–æ–¥—ã-–¥–ª—è-–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏)

---

## Collections API

### –ó–∞—á–µ–º —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ?

**Collections = –∫–ª—é—á–µ–≤–æ–π –º–µ—Ö–∞–Ω–∏–∑–º –¥–ª—è:**
- Multi-tenancy (–∏–∑–æ–ª—è—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤)
- –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –ø—Ä–æ–µ–∫—Ç–∞–º
- Access control (–∫—Ç–æ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –∫–∞–∫–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º)
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–∏ –ø–æ–∏—Å–∫–µ (search —Ç–æ–ª—å–∫–æ –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏)

### Endpoints

#### 1. CRUD Operations

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/v3/collections` | –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ |
| GET | `/v3/collections` | –°–ø–∏—Å–æ–∫ –∫–æ–ª–ª–µ–∫—Ü–∏–π —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π |
| GET | `/v3/collections/{id}` | –î–µ—Ç–∞–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ |
| POST | `/v3/collections/{id}` | –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ |
| DELETE | `/v3/collections/{id}` | –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ |

**–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ (Python SDK):**

```python
from r2r import R2RClient

client = R2RClient("http://136.119.36.216:7272")

# Create collection for a specific project
collection = client.collections.create(
    name="claude-code-project-xyz",
    description="Documentation and code context for project XYZ"
)

# Returns:
# {
#   'results': {
#     'collection_id': '123e4567-e89b-12d3-a456-426614174000',
#     'name': 'claude-code-project-xyz',
#     'description': 'Documentation and code context for project XYZ',
#     'created_at': '2025-11-19T10:00:00Z',
#     'updated_at': '2025-11-19T10:00:00Z',
#     'user_count': 0,
#     'document_count': 0
#   }
# }
```

**REST API Example:**

```bash
curl -X POST "http://136.119.36.216:7272/v3/collections" \
  -H "Authorization: Bearer ${R2R_API_KEY}" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "claude-code-project-xyz",
    "description": "Documentation and code context for project XYZ"
  }'
```

#### 2. User Management in Collections

**–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫ –∫–æ–ª–ª–µ–∫—Ü–∏–∏:**

```python
# Add user to collection (grant access)
client.collections.add_user(
    user_id="456e789f-g01h-34i5-j678-901234567890",
    collection_id="123e4567-e89b-12d3-a456-426614174000"
)

# List users in collection
users = client.collections.list_users(
    collection_id="123e4567-e89b-12d3-a456-426614174000",
    offset=0,
    limit=100
)

# Remove user from collection
client.collections.remove_user(
    user_id="456e789f-g01h-34i5-j678-901234567890",
    collection_id="123e4567-e89b-12d3-a456-426614174000"
)
```

**REST API Example:**

```bash
# Add user to collection
curl -X POST "http://136.119.36.216:7272/v3/users/{user_id}/collections/{collection_id}" \
  -H "Authorization: Bearer ${R2R_API_KEY}"

# List users in collection
curl -X GET "http://136.119.36.216:7272/v3/collections/{collection_id}/users?limit=100" \
  -H "Authorization: Bearer ${R2R_API_KEY}"
```

#### 3. Document Management in Collections

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫ –∫–æ–ª–ª–µ–∫—Ü–∏–∏:**

```python
# Add document to collection
client.collections.add_document(
    collection_id="123e4567-e89b-12d3-a456-426614174000",
    document_id="789g012j-k34l-56m7-n890-123456789012"
)

# List documents in collection
docs = client.collections.list_documents(
    collection_id="123e4567-e89b-12d3-a456-426614174000",
    offset=0,
    limit=50
)

# Get collections for a specific document
doc_collections = client.documents.list_collections(
    document_id="789g012j-k34l-56m7-n890-123456789012"
)
```

#### 4. Advanced Features

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏:**

```python
# Generate description using LLM
updated = client.collections.update(
    collection_id="123e4567-e89b-12d3-a456-426614174000",
    generate_description=True
)
# R2R –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –∏ —Å–æ–∑–¥–∞—Å—Ç summary
```

**–ü–∞–≥–∏–Ω–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è:**

```python
# Get specific collections by IDs
specific_collections = client.collections.list(
    collection_ids=['id1', 'id2', 'id3']
)

# Paginated list
paginated = client.collections.list(offset=10, limit=20)
```

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ Collections API

#### –ê —á—Ç–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ Claude Code?

**–†–µ—à–µ–Ω–∏–µ:**
```python
# Mapping: Git Repository ‚Üí R2R Collection
# Strategy: Create collection on first session start for a new project

import hashlib

def get_or_create_project_collection(repo_path: str, repo_name: str):
    # Generate stable collection name from repo path
    collection_name = f"claude-code-{repo_name}"

    # Check if collection exists
    collections = client.collections.list()
    existing = [c for c in collections['results']
                if c['name'] == collection_name]

    if existing:
        return existing[0]['collection_id']

    # Create new collection
    result = client.collections.create(
        name=collection_name,
        description=f"Auto-created for {repo_path}"
    )
    return result['results']['collection_id']
```

#### –ê —á—Ç–æ –µ—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç —É–¥–∞–ª—ë–Ω?

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è –æ—á–∏—Å—Ç–∫–∏:**
- –ü—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ ‚Üí —É–¥–∞–ª–∏—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é
- –î–æ–∫—É–º–µ–Ω—Ç—ã —Ç–∞–∫–∂–µ —É–¥–∞–ª—è—Ç—Å—è (cascade)
- OR: –ü–æ–º–µ—Ç–∏—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –∫–∞–∫ archived (—á–µ—Ä–µ–∑ metadata)

```python
# Option 1: Delete collection
client.collections.delete(collection_id)

# Option 2: Archive (update metadata)
client.collections.update(
    collection_id,
    metadata={"archived": True, "archived_at": "2025-11-19"}
)
```

#### –ê —á—Ç–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ share –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –º–µ–∂–¥—É –ø—Ä–æ–µ–∫—Ç–∞–º–∏?

**–†–µ—à–µ–Ω–∏–µ:**
- –û–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç—å –ù–ï–°–ö–û–õ–¨–ö–ò–ú –∫–æ–ª–ª–µ–∫—Ü–∏—è–º
- –°–æ–∑–¥–∞—Ç—å "shared-docs" –∫–æ–ª–ª–µ–∫—Ü–∏—é
- –î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ –æ–±–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏

```python
# Add same document to multiple collections
client.collections.add_document(collection_id="project-a", document_id="shared-doc-1")
client.collections.add_document(collection_id="project-b", document_id="shared-doc-1")

# Search will work in both collections
```

---

## Users & Authentication API

### –ó–∞—á–µ–º —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ?

**–î–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Claude Code:**
- –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ R2R API
- –†–∞–∑–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞ (–∫—Ç–æ –≤–∏–¥–∏—Ç –∫–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã)
- Token-based auth –¥–ª—è MCP Server
- Multi-user scenarios (–∫–æ–º–∞–Ω–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞–¥ –ø—Ä–æ–µ–∫—Ç–æ–º)

### Authentication Flow

#### 1. Registration & Verification

```python
# Step 1: Register new user
registration = client.users.register(
    email="developer@example.com",
    password="SecurePassword123!"
)
# User is created but INACTIVE until email verified

# Step 2: Verify email (verification code sent to email)
verification = client.users.verify_email(
    email="developer@example.com",
    verification_code="123456"
)
# Now user is ACTIVE
```

**REST API:**

```bash
# Register
curl -X POST "http://136.119.36.216:7272/v3/users/register" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "developer@example.com",
    "password": "SecurePassword123!"
  }'

# Verify
curl -X POST "http://136.119.36.216:7272/v3/users/verify-email" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "developer@example.com",
    "verification_code": "123456"
  }'
```

#### 2. Login & Token Management

```python
# Login
login_result = client.users.login(
    email="developer@example.com",
    password="SecurePassword123!"
)

# Returns:
# {
#   'results': {
#     'access_token': {
#       'token': 'eyJhbGc...',
#       'token_type': 'Bearer'
#     },
#     'refresh_token': {
#       'token': 'eyJhbGc...',
#       'token_type': 'Bearer'
#     }
#   }
# }

access_token = login_result['results']['access_token']['token']
refresh_token = login_result['results']['refresh_token']['token']
```

**Token Refresh:**

```python
# Access token expires ‚Üí refresh it
new_tokens = client.users.refresh_token(
    refresh_token=refresh_token
)

new_access_token = new_tokens['results']['access_token']['token']
new_refresh_token = new_tokens['results']['refresh_token']['token']
```

**Logout:**

```python
client.users.logout()  # Invalidates current access token
```

#### 3. User Management

```python
# Get current user info
me = client.users.me()

# Update user profile
updated = client.users.update(
    user_id=me['results']['id'],
    name="John Developer",
    bio="Full-stack developer",
    profile_picture="https://example.com/avatar.jpg"
)

# Change password
client.users.change_password(
    current_password="SecurePassword123!",
    new_password="NewSecurePassword456!"
)
```

**Password Reset Flow:**

```python
# Step 1: Request reset (sends email with reset token)
client.users.request_password_reset(
    email="developer@example.com"
)

# Step 2: Reset password with token from email
client.users.reset_password(
    reset_token="reset_token_from_email",
    new_password="RecoveredPassword789!"
)
```

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ Authentication

#### –ê —á—Ç–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Claude Code authentication?

**–ü—Ä–æ–±–ª–µ–º–∞:** Claude Code –∏–º–µ–µ—Ç —Å–≤–æ—é —Å–∏—Å—Ç–µ–º—É auth, R2R –∏–º–µ–µ—Ç —Å–≤–æ—é.

**–†–µ—à–µ–Ω–∏–µ 1: Single Service Account**
```python
# Create one R2R user for all Claude Code operations
# Store credentials in environment variables or secure vault

# In MCP Server config:
{
  "mcpServers": {
    "r2r-server": {
      "type": "http",
      "url": "http://136.119.36.216:7272",
      "headers": {
        "Authorization": "Bearer ${R2R_SERVICE_ACCOUNT_TOKEN}"
      }
    }
  }
}
```

**–†–µ—à–µ–Ω–∏–µ 2: Per-User Mapping**
```python
# Map Claude Code users to R2R users
# When Claude Code starts ‚Üí login to R2R ‚Üí get token ‚Üí use for session

def get_r2r_token_for_user(claude_user_email: str) -> str:
    # Check if R2R user exists
    # If not ‚Üí create and store credentials
    # Login and return access token
    pass
```

#### –ê —á—Ç–æ –µ—Å–ª–∏ access token expires mid-session?

**Circuit Breaker with Auto-Refresh:**

```python
class R2RAuthenticatedClient:
    def __init__(self, email: str, password: str):
        self.email = email
        self.password = password
        self.access_token = None
        self.refresh_token = None
        self._login()

    def _login(self):
        result = self.client.users.login(self.email, self.password)
        self.access_token = result['results']['access_token']['token']
        self.refresh_token = result['results']['refresh_token']['token']

    def _refresh(self):
        result = self.client.users.refresh_token(self.refresh_token)
        self.access_token = result['results']['access_token']['token']
        self.refresh_token = result['results']['refresh_token']['token']

    def call_api(self, endpoint, *args, **kwargs):
        try:
            return self._make_request(endpoint, *args, **kwargs)
        except R2RException as e:
            if e.status_code == 401:  # Token expired
                self._refresh()
                return self._make_request(endpoint, *args, **kwargs)
            raise
```

#### –ê —á—Ç–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —É–ø—Ä–∞–≤–ª—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ (superuser)?

```python
# Only superusers can list all users
all_users = client.users.list(offset=0, limit=100)

# Get specific user details
user = client.users.get(user_id="user-id")

# Delete user (superuser only)
client.users.delete(
    user_id="user-id",
    password="admin-password",
    delete_vector_data=True
)
```

---

## Orchestration & Task Monitoring

### –ó–∞—á–µ–º —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ?

**–î–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã:**
- Document ingestion –∑–∞–Ω–∏–º–∞–µ—Ç –≤—Ä–µ–º—è (chunking, embedding, summarization)
- Knowledge graph extraction = long-running task
- –ù—É–∂–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å Claude Code
- –ù—É–∂–Ω–æ retry mechanism –¥–ª—è failed tasks

### Hatchet Orchestration

**Workflows –≤ R2R:**

| Workflow | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ | –¢—Ä–∏–≥–≥–µ—Ä |
|----------|-----------|---------|
| `IngestFilesWorkflow` | Chunking, embedding, summarization –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ | `POST /v3/documents` —Å `run_with_orchestration=true` |
| `UpdateFilesWorkflow` | –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ | `POST /v3/documents/{id}` —Å `run_with_orchestration=true` |
| `KgExtractAndStoreWorkflow` | –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ entities –∏ relationships | `POST /v3/documents/{id}/extract` |
| `CreateGraphWorkflow` | –°–æ–∑–¥–∞–Ω–∏–µ knowledge graph | Graph creation endpoints |
| `EnrichGraphWorkflow` | Enrichment: node creation, clustering | Graph enrichment endpoints |

### Task Monitoring —á–µ—Ä–µ–∑ Hatchet GUI

**–î–æ—Å—Ç—É–ø –∫ Hatchet UI:**
```
URL: http://localhost:7274
Email: admin@example.com
Password: Admin123!!
```

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
- –ü—Ä–æ—Å–º–æ—Ç—Ä running workflows
- –ò–Ω—Å–ø–µ–∫—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ workflow
- Retry failed jobs
- –ü—Ä–æ—Å–º–æ—Ç—Ä long-running tasks

**–°–∫—Ä–∏–Ω—à–æ—Ç—ã workflow –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:**
- Running workflows view
- Individual workflow inspection
- Failed job retry interface

### –ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–¥–∞—á

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ—Ç –ø—Ä—è–º–æ–≥–æ API endpoint –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ `task_id`.

**–†–µ—à–µ–Ω–∏–µ:** Polling —á–µ—Ä–µ–∑ document status

```python
import time

def wait_for_ingestion(document_id: str, timeout: int = 300, poll_interval: int = 5):
    """
    Wait for document ingestion to complete

    Args:
        document_id: Document ID
        timeout: Max wait time in seconds
        poll_interval: Polling interval in seconds

    Returns:
        Document details when ready

    Raises:
        TimeoutError: If ingestion doesn't complete in time
        Exception: If ingestion fails
    """
    start_time = time.time()

    while time.time() - start_time < timeout:
        doc = client.documents.retrieve(document_id)
        status = doc['results']['ingestion_status']

        if status == 'success':
            return doc
        elif status == 'failed':
            raise Exception(f"Ingestion failed for document {document_id}")
        elif status == 'pending':
            time.sleep(poll_interval)
        else:
            raise Exception(f"Unknown status: {status}")

    raise TimeoutError(f"Ingestion timeout for document {document_id}")

# Usage
doc_result = client.documents.create(
    file_path="docs/api.md",
    run_with_orchestration=True
)
doc_id = doc_result['results']['document_id']

# Wait for completion
completed_doc = wait_for_ingestion(doc_id, timeout=300)
print(f"Document ready: {completed_doc['results']['title']}")
```

**Extraction Status Monitoring:**

```python
def wait_for_extraction(document_id: str, timeout: int = 600, poll_interval: int = 10):
    """Wait for knowledge graph extraction to complete"""
    start_time = time.time()

    while time.time() - start_time < timeout:
        doc = client.documents.retrieve(document_id)
        extraction_status = doc['results']['extraction_status']

        if extraction_status == 'success':
            # Get extracted entities and relationships
            entities = client.documents.get_entities(document_id)
            relationships = client.documents.get_relationships(document_id)
            return {
                'entities': entities,
                'relationships': relationships
            }
        elif extraction_status == 'failed':
            raise Exception(f"Extraction failed for {document_id}")
        elif extraction_status == 'pending':
            time.sleep(poll_interval)

    raise TimeoutError(f"Extraction timeout for {document_id}")
```

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ Orchestration

#### –ê —á—Ç–æ –µ—Å–ª–∏ Claude Code –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—Å—è –≤–æ –≤—Ä–µ–º—è ingestion?

**–ü—Ä–æ–±–ª–µ–º–∞:** Task –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ R2R, –Ω–æ Claude Code –ø–æ—Ç–µ—Ä—è–ª context.

**–†–µ—à–µ–Ω–∏–µ:**

```python
# SessionStart Hook: Check for pending tasks

def on_session_start():
    # Get all documents for current project collection
    docs = client.collections.list_documents(
        collection_id=project_collection_id
    )

    # Find documents with pending ingestion
    pending_docs = [
        doc for doc in docs['results']
        if doc['ingestion_status'] == 'pending'
    ]

    if pending_docs:
        print(f"‚ö†Ô∏è  Found {len(pending_docs)} documents with pending ingestion")
        print("Waiting for completion...")

        for doc in pending_docs:
            try:
                wait_for_ingestion(doc['document_id'], timeout=60)
                print(f"‚úÖ {doc['title']} is ready")
            except TimeoutError:
                print(f"‚è≥ {doc['title']} is still processing (will continue in background)")
```

#### –ê —á—Ç–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ batch processing –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤?

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è:**

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def batch_ingest_documents(file_paths: list[str], collection_id: str):
    """
    Batch ingest multiple documents with orchestration
    Returns immediately with document IDs
    Background monitoring continues
    """
    document_ids = []

    # Create all documents (starts orchestration)
    for file_path in file_paths:
        result = client.documents.create(
            file_path=file_path,
            run_with_orchestration=True,
            metadata={"collection_id": collection_id}
        )
        document_ids.append(result['results']['document_id'])

        # Add to collection
        client.collections.add_document(collection_id, result['results']['document_id'])

    print(f"üì§ Started ingestion for {len(document_ids)} documents")
    print(f"üìä Monitor progress in Hatchet UI: http://localhost:7274")

    # Background monitoring
    async def monitor_progress():
        pending = set(document_ids)
        while pending:
            await asyncio.sleep(10)
            for doc_id in list(pending):
                doc = client.documents.retrieve(doc_id)
                if doc['results']['ingestion_status'] == 'success':
                    print(f"‚úÖ {doc['results']['title']} completed")
                    pending.remove(doc_id)
                elif doc['results']['ingestion_status'] == 'failed':
                    print(f"‚ùå {doc['results']['title']} failed")
                    pending.remove(doc_id)

    # Start background monitoring
    asyncio.create_task(monitor_progress())

    return document_ids
```

#### –ê —á—Ç–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ orchestration –ë–ï–ó Hatchet (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)?

**–î–ª—è development/testing:**

```python
# Synchronous ingestion (no orchestration)
result = client.documents.create(
    file_path="docs/quick-test.md",
    run_with_orchestration=False  # Synchronous execution
)

# Document ready immediately (but slower for large files)
print(f"Document ready: {result['results']['document_id']}")
```

---

## Streaming Support

### –ó–∞—á–µ–º —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ?

**–î–ª—è –ª—É—á—à–µ–≥–æ UX –≤ Claude Code:**
- Real-time responses (–Ω–µ –∂–¥–∞—Ç—å –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞)
- –ü—Ä–æ–≥—Ä–µ—Å—Å-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
- –õ—É—á—à–µ –¥–ª—è interactive sessions

### Streaming –≤ RAG Agent

**–ü–æ–¥–¥–µ—Ä–∂–∫–∞ streaming:**
- ‚úÖ RAG Agent endpoint (`/v3/retrieval/agent`)
- ‚úÖ RAG endpoint (`/v3/retrieval/rag`)
- ‚ùì Completion endpoint (–≤–µ—Ä–æ—è—Ç–Ω–æ, –¥–∞ - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å)

**Python SDK Example:**

```python
# Streaming RAG agent response
streaming_response = client.retrieval.agent(
    message={
        "role": "user",
        "content": "Explain the architecture of this codebase"
    },
    search_settings={
        "limit": 5,
        "filters": {
            "collection_id": {"$eq": project_collection_id}
        }
    },
    rag_generation_config={
        "model": "gpt-4",
        "temperature": 0.7,
        "max_tokens": 500,
        "stream": True  # Enable streaming
    },
    conversation_id=conversation_id
)

# Stream response chunks
print("ü§ñ Assistant: ", end="", flush=True)
for chunk in streaming_response:
    print(chunk, end="", flush=True)
print()  # Newline at end
```

**REST API Example (curl):**

```bash
# Streaming with curl
curl -X POST "http://136.119.36.216:7272/v3/retrieval/agent" \
  -H "Authorization: Bearer ${R2R_API_KEY}" \
  -H "Content-Type: application/json" \
  -d '{
    "message": {
      "role": "user",
      "content": "Explain the architecture"
    },
    "rag_generation_config": {
      "stream": true
    }
  }' \
  --no-buffer  # Important: disable buffering for streaming
```

### Streaming Protocol

**–í–µ—Ä–æ—è—Ç–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª:** Server-Sent Events (SSE) –∏–ª–∏ chunked transfer encoding

**Response format (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ):**

```
data: {"chunk": "The architecture "}
data: {"chunk": "consists of "}
data: {"chunk": "multiple layers..."}
data: [DONE]
```

**Note:** –¢–æ—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤ —Ä–µ–∞–ª—å–Ω–æ–º API –∏–ª–∏ –ø–æ–ª–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ Streaming

#### –ê —á—Ç–æ –µ—Å–ª–∏ streaming connection –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç—Å—è?

**Error Handling:**

```python
import time

def stream_with_retry(client, message, max_retries=3, retry_delay=2):
    """Stream with automatic retry on connection failure"""
    for attempt in range(max_retries):
        try:
            response = client.retrieval.agent(
                message=message,
                rag_generation_config={"stream": True}
            )

            chunks = []
            for chunk in response:
                print(chunk, end="", flush=True)
                chunks.append(chunk)

            return "".join(chunks)

        except ConnectionError as e:
            if attempt < max_retries - 1:
                print(f"\n‚ö†Ô∏è  Connection lost, retrying in {retry_delay}s...")
                time.sleep(retry_delay)
                retry_delay *= 2  # Exponential backoff
            else:
                raise Exception(f"Streaming failed after {max_retries} attempts")
```

#### –ê —á—Ç–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω partial response –ø—Ä–∏ –æ—à–∏–±–∫–µ?

**Buffered Streaming:**

```python
def buffered_stream(client, message, buffer_size=100):
    """
    Stream with buffering
    If connection fails, at least we have partial response
    """
    response_buffer = []

    try:
        response = client.retrieval.agent(
            message=message,
            rag_generation_config={"stream": True}
        )

        for chunk in response:
            response_buffer.append(chunk)
            print(chunk, end="", flush=True)

            # Save checkpoint every N chunks
            if len(response_buffer) % buffer_size == 0:
                save_checkpoint(response_buffer)

        return "".join(response_buffer)

    except Exception as e:
        print(f"\n‚ùå Streaming failed: {e}")
        print(f"üìù Partial response ({len(response_buffer)} chunks):")
        return "".join(response_buffer)
```

---

## Rate Limiting & Performance

### –ó–∞—á–µ–º —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ?

**–î–ª—è production deployment:**
- –ò–∑–±–µ–∂–∞—Ç—å throttling –æ—Ç R2R API
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è batch operations
- Cost control (API calls –º–æ–≥—É—Ç –±—ã—Ç—å –ø–ª–∞—Ç–Ω—ã–º–∏)
- Resource management

### Rate Limiting Configuration

**–í R2R —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è:**
- `concurrent_request_limit` –¥–ª—è embedding providers
- Provider-specific rate limits

**–ì–¥–µ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è:** `r2r.toml` configuration file

**Example Configuration:**

```toml
[embedding]
provider = "openai"
base_model = "text-embedding-3-small"
base_dimension = 512
batch_size = 128
concurrent_request_limit = 256  # Max concurrent requests
```

### Performance Optimization Strategies

#### 1. Batch Size Optimization

**Trade-offs:**
- ‚úÖ Larger batch = better throughput
- ‚ùå Larger batch = higher latency
- ‚ùå Larger batch = more memory usage

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**

```toml
# For real-time applications
[embedding]
batch_size = 32
concurrent_request_limit = 64

# For batch processing
[embedding]
batch_size = 256
concurrent_request_limit = 512
```

#### 2. Vector Index Optimization

**HNSW Parameters:**

```python
# Balanced configuration
client.indices.create(
    table_name="vectors",
    index_method="hnsw",
    index_measure="cosine_distance",
    index_arguments={
        "m": 16,  # Connections per element (16-64)
        "ef_construction": 64  # Build quality (64-100)
    }
)

# High-quality configuration (slower build, better search)
client.indices.create(
    table_name="vectors",
    index_method="hnsw",
    index_arguments={
        "m": 32,
        "ef_construction": 80
    }
)
```

**Index Pre-warming:**

```python
# Indices start "cold" and need warming
# First queries will be slow until index loads into memory

def prewarm_index(client, sample_queries: list[str]):
    """Execute sample queries to warm up the index"""
    print("üî• Pre-warming vector index...")
    for query in sample_queries:
        client.retrieval.search(query, search_settings={"limit": 5})
    print("‚úÖ Index pre-warmed")
```

#### 3. Search Performance Optimization

**Multi-user filtering:**

```python
# Efficient: Filter by user_id or collection_id
# Reduces vector search space significantly

response = client.retrieval.search(
    query="authentication implementation",
    search_settings={
        "filters": {
            "collection_id": {"$eq": project_collection_id}
        },
        "limit": 10
    }
)
```

**Hybrid Search Tuning:**

```python
# Adjust weights for better results
response = client.retrieval.search(
    query="how to implement OAuth",
    search_settings={
        "use_hybrid_search": True,
        "hybrid_settings": {
            "full_text_weight": 1.0,   # Keyword importance
            "semantic_weight": 5.0,    # Semantic importance
            "full_text_limit": 200,    # Max full-text results
            "rrf_k": 50                # RRF parameter
        }
    }
)
```

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ Performance

#### –ê —á—Ç–æ –µ—Å–ª–∏ R2R instance –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω?

**Circuit Breaker Pattern:**

```python
import time
from enum import Enum

class CircuitState(Enum):
    CLOSED = "closed"      # Normal operation
    OPEN = "open"          # Failing, reject requests
    HALF_OPEN = "half_open"  # Testing recovery

class R2RCircuitBreaker:
    def __init__(self, failure_threshold=3, timeout=60):
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.last_failure_time = None
        self.state = CircuitState.CLOSED

    def call(self, func, *args, **kwargs):
        if self.state == CircuitState.OPEN:
            if time.time() - self.last_failure_time > self.timeout:
                self.state = CircuitState.HALF_OPEN
                print("üîÑ Circuit breaker: testing recovery...")
            else:
                raise Exception("Circuit breaker is OPEN - R2R unavailable")

        try:
            result = func(*args, **kwargs)

            if self.state == CircuitState.HALF_OPEN:
                self.state = CircuitState.CLOSED
                self.failure_count = 0
                print("‚úÖ Circuit breaker: recovered")

            return result

        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()

            if self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN
                print(f"‚ö†Ô∏è  Circuit breaker: OPEN after {self.failure_count} failures")

            raise

# Usage
breaker = R2RCircuitBreaker(failure_threshold=3, timeout=60)

try:
    result = breaker.call(
        client.retrieval.search,
        query="test query",
        search_settings={"limit": 5}
    )
except Exception as e:
    print(f"‚ùå Request failed: {e}")
```

#### –ê —á—Ç–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ scaling –¥–ª—è production?

**Scaling Strategies –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:**

1. **Horizontal Scaling:**
   - Multiple R2R instances –∑–∞ load balancer
   - Shard by `user_id` –¥–ª—è multi-user apps

2. **Vertical Scaling:**
   - AWS RDS –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ 1B vectors per instance
   - `db.r6g.16xlarge`: –¥–æ 100M vectors
   - `db.r6g.metal`: 1B+ vectors

3. **Resource Allocation:**
   - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ per-user usage
   - Usage quotas
   - Dedicated instances –¥–ª—è power users

**Performance Metrics to Monitor:**

```python
# Metrics to track:
# - Average query latency per user
# - Number of vectors searched per query
# - Cache hit rates
# - Memory usage per instance
# - CPU utilization
# - Storage growth rate
```

---

## –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

### –ß—Ç–æ –º—ã —Ç–µ–ø–µ—Ä—å –∑–Ω–∞–µ–º?

#### 1. Collections API ‚úÖ

**–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**
- –ü–æ–ª–Ω—ã–π CRUD
- Multi-tenancy support
- –ì–∏–±–∫–∞—è —Å–≤—è–∑—å users ‚Üî collections ‚Üî documents
- –ü–∞–≥–∏–Ω–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è

**–î–ª—è Claude Code:**
- ‚úÖ –ú–æ–∂–µ–º —Å–æ–∑–¥–∞—Ç—å collection per project
- ‚úÖ –ú–æ–∂–µ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å search –ø–æ collection
- ‚úÖ –ú–æ–∂–µ–º share docs –º–µ–∂–¥—É projects
- ‚úÖ –ú–æ–∂–µ–º —É–ø—Ä–∞–≤–ª—è—Ç—å access (–µ—Å–ª–∏ multi-user)

#### 2. Users & Auth API ‚úÖ

**–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**
- Bearer token authentication
- Refresh token mechanism
- Password reset flow
- User metadata (name, bio, avatar)

**–î–ª—è Claude Code:**
- ‚úÖ Service account strategy
- ‚úÖ Per-user mapping strategy (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- ‚úÖ Auto-refresh –¥–ª—è long sessions
- ‚ö†Ô∏è  Need to store credentials securely (env vars or vault)

#### 3. Orchestration ‚úÖ

**–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**
- Hatchet = robust task queue
- Fault tolerance –∏ retry
- GUI –¥–ª—è monitoring
- Long-running tasks support

**–î–ª—è Claude Code:**
- ‚úÖ Background ingestion –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç user
- ‚úÖ –ú–æ–∂–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å (polling)
- ‚úÖ SessionStart hook –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç context –ø—Ä–∏ restart
- ‚ö†Ô∏è  –ù–µ—Ç webhook notifications (–Ω—É–∂–µ–Ω polling)

#### 4. Streaming ‚úÖ

**–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**
- RAG agent streaming
- Real-time UX
- Chunked responses

**–î–ª—è Claude Code:**
- ‚úÖ –ú–æ–∂–µ–º –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å progressive responses
- ‚úÖ Better UX –¥–ª—è interactive sessions
- ‚ö†Ô∏è  Need error handling –¥–ª—è connection drops

#### 5. Rate Limiting & Performance ‚úÖ

**–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**
- Configurable batch sizes
- Vector index optimization
- Multi-user filtering
- Horizontal –∏ vertical scaling

**–î–ª—è Claude Code:**
- ‚úÖ Circuit breaker pattern –¥–ª—è resilience
- ‚úÖ Pre-warming indices –¥–ª—è better performance
- ‚úÖ Collection filtering —É–º–µ–Ω—å—à–∞–µ—Ç search space
- ‚ö†Ô∏è  Need monitoring –¥–ª—è production

### –û—Å—Ç–∞–≤—à–∏–µ—Å—è –≤–æ–ø—Ä–æ—Å—ã

#### 1. Webhooks –¥–ª—è task completion?

**–í–æ–ø—Ä–æ—Å:** –ï—Å—Ç—å –ª–∏ webhooks –≤–º–µ—Å—Ç–æ polling –¥–ª—è ingestion status?

**–¢–µ–∫—É—â–µ–µ —Ä–µ—à–µ–Ω–∏–µ:** Polling —á–µ—Ä–µ–∑ `GET /v3/documents/{id}`

**–õ—É—á—à–µ –±—ã:** Webhook callback –ø—Ä–∏ completion
```json
POST https://claude-code-webhook.example.com/r2r/ingestion-complete
{
  "document_id": "...",
  "status": "success",
  "collection_id": "...",
  "metadata": {...}
}
```

#### 2. Bulk operations –¥–ª—è documents?

**–í–æ–ø—Ä–æ—Å:** –ú–æ–∂–Ω–æ –ª–∏ batch create –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º?

**–¢–µ–∫—É—â–µ–µ —Ä–µ—à–µ–Ω–∏–µ:** Loop —á–µ—Ä–µ–∑ single creates
```python
for file in files:
    client.documents.create(file)  # N requests
```

**–õ—É—á—à–µ –±—ã:** Batch endpoint
```python
client.documents.batch_create(files)  # 1 request
```

#### 3. Cost tracking?

**–í–æ–ø—Ä–æ—Å:** –ï—Å—Ç—å –ª–∏ metrics –¥–ª—è API usage –∏ cost?

**–ù—É–∂–Ω–æ –¥–ª—è production:**
- API calls per user
- Token usage (for embeddings/generation)
- Cost estimation
- Usage alerts

#### 4. Data retention policies?

**–í–æ–ø—Ä–æ—Å:** Auto-cleanup —Å—Ç–∞—Ä—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤?

**–ù—É–∂–Ω–æ:**
- TTL –¥–ª—è documents
- Archive instead of delete
- Compliance (GDPR right to be forgotten)

---

## –í—ã–≤–æ–¥—ã –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å R2R API

**–û—Ü–µ–Ω–∫–∞ –ø–æ –∫—Ä–∏—Ç–∏—á–Ω—ã–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º:**

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å | –û—Ü–µ–Ω–∫–∞ | –ó–∞–º–µ—Ç–∫–∏ |
|-----------|------------|--------|---------|
| Collections API | ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é | 10/10 | –û—Ç–ª–∏—á–Ω–æ –¥–ª—è multi-project isolation |
| Users & Auth | ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é | 9/10 | Service account strategy —Ä–∞–±–æ—Ç–∞–µ—Ç |
| Orchestration | ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ | 8/10 | Polling –≤–º–µ—Å—Ç–æ webhooks - –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ |
| Streaming | ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ | 8/10 | Supported –≤ key endpoints |
| Rate Limiting | ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ | 7/10 | Configurable, –Ω–æ –Ω—É–∂–µ–Ω monitoring |
| Task Monitoring | ‚ö†Ô∏è  –ß–∞—Å—Ç–∏—á–Ω–æ | 6/10 | –ù–µ—Ç –ø—Ä—è–º–æ–≥–æ API, —Ç–æ–ª—å–∫–æ polling |
| Webhooks | ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç | 3/10 | –ù—É–∂–µ–Ω –¥–ª—è production-grade integration |

**–û–±—â–∞—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Claude Code: 8/10** ‚úÖ

### –ß—Ç–æ –º–æ–∂–Ω–æ –¥–µ–ª–∞—Ç—å –°–ï–ô–ß–ê–°

1. ‚úÖ Create collection per Claude Code project
2. ‚úÖ Upload documentation to R2R asynchronously
3. ‚úÖ Search within project-specific collection
4. ‚úÖ RAG agent –¥–ª—è context-aware responses
5. ‚úÖ Store conversations –≤ R2R Conversations API
6. ‚úÖ Stream responses –¥–ª—è better UX
7. ‚úÖ Monitor ingestion —á–µ—Ä–µ–∑ polling
8. ‚úÖ Circuit breaker –¥–ª—è resilience

### –ß—Ç–æ —Ç—Ä–µ–±—É–µ—Ç workarounds

1. ‚ö†Ô∏è  Webhook notifications ‚Üí Polling —Å reasonable intervals
2. ‚ö†Ô∏è  Batch operations ‚Üí Loop —Å rate limiting
3. ‚ö†Ô∏è  Cost tracking ‚Üí Application-level metrics
4. ‚ö†Ô∏è  Data retention ‚Üí Manual cleanup scripts

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Gap Analysis

#### Solution 1: Service Account Strategy ‚úÖ (Recommended)

```python
# Single R2R user for all Claude Code operations
# Stored in secure env vars

R2R_SERVICE_EMAIL=claude-code-service@example.com
R2R_SERVICE_PASSWORD=<secure-password>

# MCP Server authenticates once at startup
# Refreshes token automatically when needed
```

**Pros:**
- Simple setup
- No per-user R2R accounts needed
- Centralized credential management

**Cons:**
- No per-user permissions (if multi-user Claude Code)
- All operations logged under service account

#### Solution 2: Polling-Based Task Monitoring ‚úÖ

```python
# SessionStart Hook: Resume pending tasks
# PostToolUse Hook: Trigger ingestion, start monitoring
# Background thread: Poll ingestion status

def background_monitor():
    while True:
        pending = get_pending_documents()
        for doc_id in pending:
            status = client.documents.retrieve(doc_id)['results']['ingestion_status']
            if status == 'success':
                notify_user(f"‚úÖ {doc['title']} is ready")
            elif status == 'failed':
                notify_user(f"‚ùå {doc['title']} failed")
        time.sleep(30)  # Poll every 30s
```

**Pros:**
- Works with current R2R API
- Reliable (doesn't miss completions)

**Cons:**
- Additional polling requests
- 30s latency for notifications

#### Solution 3: Collection-Per-Project Mapping ‚úÖ

```python
# Mapping strategy
{
  "project_path": "/home/user/my-app",
  "collection_id": "123e4567-...",
  "collection_name": "claude-code-my-app",
  "created_at": "2025-11-19T10:00:00Z"
}

# Store mapping in local file or R2R collection metadata
```

**Pros:**
- Clean isolation between projects
- Efficient search (only within project docs)
- Easy to delete all project docs

**Cons:**
- Need to manage mapping (local file or database)

---

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

### Immediate Actions

1. ‚úÖ Gap Analysis –∑–∞–≤–µ—Ä—à—ë–Ω
2. ‚è≠Ô∏è MCP Server Detailed Specification
   - Auth strategy (service account)
   - Tools: search, ingest, monitor_tasks, list_collections
   - Caching layer
   - Circuit breaker implementation
3. ‚è≠Ô∏è Data Consistency Strategy
   - Queue –¥–ª—è document updates (avoid race conditions)
   - Versioning strategy
   - Idempotency guarantees
4. ‚è≠Ô∏è Testing Strategy
   - Unit tests –¥–ª—è MCP server
   - Integration tests –¥–ª—è workflows
   - E2E tests
   - Performance benchmarks

---

## –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ

- **–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞**: 1.0
- **–°—Ç–∞—Ç—É—Å**: Gap Analysis –∑–∞–≤–µ—Ä—à—ë–Ω
- **–°–ª–µ–¥—É—é—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç**: MCP Server Specification
- **–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å**: ‚úÖ HIGH - –í—Å–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∑–∞–ø–æ–ª–Ω–µ–Ω—ã
- **–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ Phase 4**: ‚úÖ YES - –º–æ–∂–µ–º –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –∫ Technical Specification

---

## Appendix: Quick Reference

### Collections API

```python
# Create
collection = client.collections.create(name, description)

# Add user
client.collections.add_user(user_id, collection_id)

# Add document
client.collections.add_document(collection_id, document_id)

# List documents
docs = client.collections.list_documents(collection_id, offset=0, limit=50)
```

### Auth API

```python
# Login
tokens = client.users.login(email, password)
access_token = tokens['results']['access_token']['token']

# Refresh
new_tokens = client.users.refresh_token(refresh_token)

# Logout
client.users.logout()
```

### Orchestration

```python
# Async ingestion
result = client.documents.create(file_path, run_with_orchestration=True)
doc_id = result['results']['document_id']

# Monitor
status = client.documents.retrieve(doc_id)['results']['ingestion_status']
# Status: 'pending' | 'success' | 'failed'
```

### Streaming

```python
# Stream RAG response
response = client.retrieval.agent(
    message={"role": "user", "content": "..."},
    rag_generation_config={"stream": True}
)

for chunk in response:
    print(chunk, end="", flush=True)
```
